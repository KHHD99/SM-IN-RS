{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MICROSOFT RECOMMENDER, SAR ALGORITHM  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import scrapbook as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy, logging, sys, warnings, joblib\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "\n",
    "import recommenders\n",
    "from recommenders.models.sar import SAR \n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.utils.python_utils import binarize\n",
    "from recommenders.datasets.python_splitters import python_stratified_split\n",
    "from recommenders.evaluation.python_evaluation import (precision_at_k, mae, rsquared)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a list of top_k items that will be recommended to users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_top_k=[3, 5, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "\tMovieTweetings dataset\n",
    "    \n",
    "https://www.kaggle.com/datasets/tunguz/movietweetings \n",
    "\n",
    "https://github.com/sidooms/MovieTweetings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the the Movietweetings (Electronic) dataset after that we add the columns names as \n",
    "# userID, itemID, rating\n",
    "data=pd.read_csv('MT_ratings.dat',sep='::')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[:50000]\n",
    "#data=data.sample(n=50000, random_state=0)\n",
    "#data=data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of dataset\n",
    "print('shape of the dataset:',data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the ratings to float32 to reduce memory usage\n",
    "data['rating'] = data['rating'].astype(np.float32)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again the number of messing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into train and test sets\n",
    "\t75% train set and 25% test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_stratified_split(data, \n",
    "                                      ratio=0.75,\n",
    "                                      col_user='userID',\n",
    "                                      col_item='itemID',\n",
    "                                      seed=0)\n",
    "(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\n",
    "f\"\"\"Train: \n",
    "Total Ratings: {len(train)}\n",
    "Unique Users:  {len(train['userID'].unique())}\n",
    "Unique Items:  {len(train['itemID'].unique())}\n",
    "\"\"\"\n",
    "     )\n",
    "\n",
    "print(\n",
    "f\"\"\"Test: \n",
    "Total Ratings: {len(test)}\n",
    "Unique Users:  {len(test['userID'].unique())}\n",
    "Unique Items:  {len(test['itemID'].unique())}\n",
    "\"\"\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the list of the similarities that will be investigated\n",
    "Similarity type must be one of available similarity metrics:\n",
    "\t\n",
    "- \"cooccurrence\", \"jaccard\", \"lift\", \"HD_JACCARD\", \"DICE\", \"JACCARD_3W\", \"SOKAL_SNEATH_I\", \"COSINE\", \"SORGENFREI\", \"MOUNTFORD\", \"MCCONNAUGHEY\", \"KULCZYNSKI_II\", \"DRIVER_KROEBER\", \"JOHNSON\", \"SIMPSON\", \"BRAUN_BANQUET\", \"FAGER_MCGOWAN\", \"EUCLID\", \"MINKOWSKI\", \"LANCE_WILLIAMS\", \"HELLINGER\", \"CHORD\",\n",
    " \n",
    " \n",
    "- \"SOKAL_MICHENER\", \"SOKAL_SNEATH_II\", \"SOKAL_SNEATH_IV\", \"SOKAL_SNEATH_V\",  \"PEARSON_I\", \"PEARSON_II\", \"PEARSON_III\", \"PEARSON_HERON_I\", \"PEARSON_HERON_II\", \"BARONI_URBANI_BUSER_I\", \"BARONI_URBANI_BUSER_II\", \"FORBES_I\", \"FORBES_II\", \"YULEQ\", \"YULEQ_W\", \"TARANTULA\", \"AMPLE\", \"ROGERS_TANIMOTO\", \"FAITH\", \"GOWER_LEGENDRE\", \"INNERPRODUCT\", \"RUSSELL_RAO\", \"TARWID\", \"DENNIS\", \"GOWER\", \"STILES\", \"FOSSUM\", \"DISPERSON\", \"HAMANN\", \"MICHAEL\", \"PEIRCE\", \"EYRAUD\", \"YULEQ_D\", \"MEAN_MANHATTAN\", \"VARI\", \"SHAPEDIFFERENCE\", \"PATTERNDIFFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of the similarity metrics that already implemented in SAR algorithm\n",
    "list_already_exist=[\n",
    "    \"jaccard\" , \n",
    "    \"lift\"\n",
    "    ]\n",
    "print(len(list_already_exist),'similarity metrics already implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the list of the similarity metrics without negative co-occurrences\n",
    "list_metrics=[\n",
    "    # similarities\n",
    "    \"DICE\", \"JACCARD_3W\", \"SOKAL_SNEATH_I\", \"COSINE\",\n",
    "    \"SORGENFREI\", \"MOUNTFORD\",\"KULCZYNSKI_II\", \n",
    "    \"JOHNSON\",\"SIMPSON\", \"BRAUN_BANQUET\", \"FAGER_MCGOWAN\",\n",
    "    # distances\n",
    "    \"EUCLID\", \"MINKOWSKI\", \"LANCE_WILLIAMS\", \"HELLINGER\", \"CHORD\"\n",
    "    ]\n",
    "print(len(list_metrics),'similarity metrics without d')\n",
    "# \"MCCONNAUGHEY\",\"DRIVER_KROEBER\": 0 SAMPLES IN PREDICTION SO CANNOT COMPUTE MAE, R², AND P@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the list of the similarity metrics with negative co-occurrences\n",
    "list_metrics_d=[\n",
    "# similarities with negative co-occurrences \n",
    "\"SOKAL_MICHENER\", \"SOKAL_SNEATH_II\", \"SOKAL_SNEATH_IV\", \"SOKAL_SNEATH_V\",  \"PEARSON_I\", \n",
    "\"PEARSON_II\", \"PEARSON_III\", \"PEARSON_HERON_I\", \"PEARSON_HERON_II\", \"BARONI_URBANI_BUSER_I\", \n",
    "\"BARONI_URBANI_BUSER_II\",  \"FORBES_I\",  \"FORBES_II\", \"YULEQ\", \"YULEQ_W\", \n",
    "\"ROGERS_TANIMOTO\", \"FAITH\",  \"GOWER_LEGENDRE\", \"INNERPRODUCT\", \"RUSSELL_RAO\", \"TARWID\",\n",
    "\"DENNIS\", \"GOWER\",  \"STILES\", \"FOSSUM\", \"DISPERSON\",  \"HAMANN\",  \"MICHAEL\", \"PEIRCE\", \"EYRAUD\",\n",
    "\n",
    "# distances with negative co-occurrences \n",
    "\"YULEQ_D\", \"MEAN_MANHATTAN\", \"VARI\", \"PATTERNDIFFERENCE\" ]\n",
    "\n",
    "print(len(list_metrics_d),'similarity metrics with d')\n",
    "#\"TARANTULA\", \"AMPLE\", \"FOSSUM\": 0 SAMPLES IN PREDICTIONS SO CANNOT COMPUTE MAE, R², AND P@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combine all similarities to train them in the sar algorithm \n",
    "list_all_metrics=list_already_exist+list_metrics+list_metrics_d\n",
    "print('Total N° of SM: ',len(list_all_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization  of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_models=[]\n",
    "for metric in list_all_metrics:\n",
    "    model                  = SAR(\n",
    "    col_user               = \"userID\",\n",
    "    col_item               = \"itemID\",\n",
    "    col_rating             = \"rating\",\n",
    "    similarity_type        =  metric,    \n",
    "    normalize              =  True, \n",
    "    # IF THERE IN NO TIMESTAMP IN THE DATASET THEN COMMENT THE FOLLOWING LINES\n",
    "    time_decay_coefficient =  30, \n",
    "    timedecay_formula      =  True,\n",
    "    col_timestamp          = \"timestamp\"\n",
    "    )\n",
    "    \n",
    "    list_models.append(model)\n",
    "print('Initiated models : ',len(list_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as train_time:\n",
    "    i=0\n",
    "    for model in list_models:\n",
    "        model.fit(train)\n",
    "        print(f\"model_{i+1}_{list_all_metrics[i]} trained.\")\n",
    "        # save the model to disk to make checkpoints \n",
    "        filename = f'model_{i+1}_{list_all_metrics[i]}.sav'\n",
    "        joblib.dump(model, filename)  \n",
    "        print(f\"model_{i+1}_{list_all_metrics[i]} saved.\")\n",
    "        i+=1\n",
    "\n",
    "print(f\"Took {train_time.interval} seconds for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All models are trained and saved into disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved models\n",
    "list_models=[]\n",
    "for i in range(len(list_all_metrics)):\n",
    "    #print(filename)\n",
    "    filename = f'model_{i+1}_{list_all_metrics[i]}.sav'\n",
    "    loaded_model = joblib.load(filename)\n",
    "    list_models.append(loaded_model)\n",
    "    del loaded_model\n",
    "\n",
    "print('list_loaded_model:',len(list_models))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make recommendations (predictions) : top_k=3,5,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate the recommendations\n",
    "list_of_list_k_items=[]\n",
    "with Timer() as test_time:\n",
    "    for i in list_top_k:\n",
    "        print(f'Recommending Top_{i}')\n",
    "        list_models_K_items=[]\n",
    "        for model in list_models:\n",
    "            list_models_K_items.append(model.recommend_k_items(test,i,remove_seen=True))\n",
    "        list_of_list_k_items.append(list_models_K_items)\n",
    "        print(f'Top_k_{i} is done')\n",
    "        del list_models_K_items\n",
    "print(f\"Took {test_time.interval} seconds for prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predicions\n",
    "with open(\"prediction\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(list_of_list_k_items, fp)\n",
    "print('All predictions are saved into disck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the predictions\n",
    "with open(\"prediction\", \"rb\") as fp:   # Unpickling\n",
    "    list_of_list_k_items = pickle.load(fp)\n",
    "len(list_of_list_k_items)\n",
    "print('All predictions are loaded from disck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\tcompute the MAE, P@K, and R² for each Top_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_list_PRECISION, list_of_list_MAE, list_of_list_R_SQUARED=[], [], []\n",
    "for i in range(len(list_top_k)):\n",
    "    list_MAE_1,list_PRECISION_1,list_R_SQUARED_1=[], [], []\n",
    "    j=1\n",
    "    for top_k in list_of_list_k_items[i]:\n",
    "        list_MAE_1.append(mae(test, top_k, col_user='userID', col_item='itemID', col_rating='rating'))\n",
    "        list_R_SQUARED_1.append(rsquared(test, top_k, col_user='userID', col_item='itemID', col_rating='rating'))\n",
    "        list_PRECISION_1.append(precision_at_k(test, top_k, col_user='userID', col_item='itemID', col_rating='rating', \n",
    "                                               k=list_top_k[i]))\n",
    "        #print(j)\n",
    "        j+=1\n",
    "    print(f'list for Top_k={list_top_k[i]} done')\n",
    "    list_of_list_MAE.append(list_MAE_1)\n",
    "    list_of_list_PRECISION.append(list_PRECISION_1)\n",
    "    list_of_list_R_SQUARED.append(list_R_SQUARED_1)\n",
    "    del list_MAE_1,list_PRECISION_1,list_R_SQUARED_1\n",
    "\n",
    "positivity_threshold = 2\n",
    "test_bin             = test.copy()\n",
    "test_bin['rating']   = binarize(test_bin['rating'], positivity_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make difference between the similarity metrics without negative cooccurrences \n",
    "# and similarity metrics without negative cooccurrences\n",
    "#Define the list of the similarity metrics with negative co-occurrences\n",
    "list_metrics_dd=[\n",
    "# similarities with negative co-occurrences \n",
    "\"D_SOKAL_MICHENER\", \"D_SOKAL_SNEATH_II\", \"D_SOKAL_SNEATH_IV\",  \"D_PEARSON_I\", \"D_SOKAL_SNEATH_V\",\n",
    "\"D_PEARSON_II\", \"D_PEARSON_III\", \"D_PEARSON_HERON_I\", \"D_PEARSON_HERON_II\", \"D_BARONI_URBANI_BUSER_I\", \n",
    "\"D_BARONI_URBANI_BUSER_II\",  \"D_FORBES_I\",  \"D_FORBES_II\", \"D_YULEQ\", \"D_YULEQ_W\",  \n",
    "\"D_ROGERS_TANIMOTO\", \"D_FAITH\",  \"D_GOWER_LEGENDRE\", \"D_INNERPRODUCT\", \"D_RUSSELL_RAO\",\n",
    "\"D_TARWID\", \"D_DENNIS\", \"D_GOWER\",  \"D_STILES\", \"D_DISPERSON\",  \"D_HAMANN\", \n",
    "\"D_MICHAEL\", \"D_PEIRCE\", \"D_EYRAUD\",\n",
    "\n",
    "# distances with negative co-occurrences \n",
    "\"D_YULEQ_D\", \"D_MEAN_MANHATTAN\", \"D_VARI\", \"D_SHAPEDIFFERENCE\", \"D_PATTERNDIFFERENCE\" ]\n",
    "\n",
    "print(len(list_metrics_dd),'similarity metrics with d and a prefix D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dic=[]\n",
    "for i in range(len(list_top_k)):\n",
    "    dic={\n",
    "        \"Top K\": list_top_k[i],\n",
    "        \"MAE\": list_of_list_MAE[i],\n",
    "        \"Precision@K\": list_of_list_PRECISION[i],\n",
    "        \"R2\": list_of_list_R_SQUARED[i],\n",
    "        }\n",
    "    list_dic.append(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dataframe=[]\n",
    "for i in range(len(list_top_k)):\n",
    "    dataframe=pd.DataFrame.from_dict(list_dic[i])\n",
    "    dataframe.index=list_already_exist+list_metrics+list_metrics_dd\n",
    "    list_dataframe.append(dataframe)\n",
    "    dataframe.to_excel(f\"Evaluation_Matrix_Top{list_top_k[i]}.xlsx\")\n",
    "    del dataframe"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "display(list_dataframe[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA=list_dataframe[0]\n",
    "for i in range(1,len(list_top_k)):\n",
    "    DATA=pd.concat([DATA, list_dataframe[i]], axis=0)\n",
    "DATA.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the tables a Excel format\n",
    "DATA.to_excel(\"Evaluation Metrics Top_3_5_10.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=len(list_already_exist+list_metrics)\n",
    "split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the MAE, P@K, and R² for the similarity metric without negative co-occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #list_dataframe[0][:split].sort_values(\"MAE\",ascending=False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3 , figsize=(20,8))\n",
    "col=['r','g','b']\n",
    "for i in range(len(list_top_k)):\n",
    "    data=list_dataframe[i][:split][['MAE']].sort_values(by='MAE',ascending=True)\n",
    "    data['MAE'].plot(ax=axes[i], kind='bar', color=col[i], legend='MAE', x='Similarity', )\n",
    "    axes[i].set_title(f'Top {list_top_k[i]}')\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "    fig.savefig(\"1M_MAE.jpg\", bbox_inches='tight', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3 , figsize=(20,8))\n",
    "col=['r','g','b']\n",
    "for i in range(len(list_top_k)):\n",
    "    data=list_dataframe[i][:split][['R2']].sort_values(by='R2',ascending=True)\n",
    "    data['R2'].plot(ax=axes[i], kind='bar', color=col[i], y='R2', x='Similarity', )\n",
    "    axes[i].set_title(f'Top {list_top_k[i]}')\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "    fig.savefig(\"1M_R2.jpg\", bbox_inches='tight', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3 , figsize=(20,8))\n",
    "col=['r','g','b']\n",
    "for i in range(len(list_top_k)):\n",
    "    data=list_dataframe[i][:split][['Precision@K']].sort_values(by='Precision@K',ascending=True)\n",
    "    data['Precision@K'].plot(ax=axes[i], kind='bar', color=col[i], y='Precision@K', x='Similarity', )\n",
    "    axes[i].set_title(f'Top {list_top_k[i]}')\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "    fig.savefig(\"1M_P@K.jpg\", bbox_inches='tight', dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the MAE, P@K, and R² for the similarity metrics with negative co-occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #list_dataframe[0][split:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3 , figsize=(20,8))\n",
    "col=['r','g','b']\n",
    "for i in range(len(list_top_k)):\n",
    "    data=list_dataframe[i][split:][['MAE']].sort_values(by='MAE',ascending=True)\n",
    "    data['MAE'].plot(ax=axes[i], kind='bar', color=col[i], legend='MAE', x='Similarity', )\n",
    "    axes[i].set_title(f'Top {list_top_k[i]}')\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "    fig.savefig(\"1M_D_MAE.jpg\", bbox_inches='tight', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3 , figsize=(20,8))\n",
    "col=['r','g','b']\n",
    "for i in range(len(list_top_k)):\n",
    "    data=list_dataframe[i][split:][['R2']].sort_values(by='R2',ascending=True)\n",
    "    data['R2'].plot(ax=axes[i], kind='bar', color=col[i], y='R2', x='Similarity', )\n",
    "    axes[i].set_title(f'Top {list_top_k[i]}')\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "    fig.savefig(\"1M_D_R2.jpg\", bbox_inches='tight', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3 , figsize=(20,8))\n",
    "col=['r','g','b']\n",
    "for i in range(len(list_top_k)):\n",
    "    data=list_dataframe[i][split:][['Precision@K']].sort_values(by='Precision@K',ascending=True)\n",
    "    data['Precision@K'].plot(ax=axes[i], kind='bar', color=col[i], y='Precision@K', x='Similarity', )\n",
    "    axes[i].set_title(f'Top {list_top_k[i]}')\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "    fig.savefig(\"1M_D_P@K.jpg\", bbox_inches='tight', dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the clustering of the similarity metrics with CAH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_top_k)):\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    Z = linkage(list_dataframe[i].drop('R2',axis=1),method='ward',metric='euclidean') \n",
    "    # complete average ward single\n",
    "    plt.title(f\"CAH_METRICS :Top_{list_top_k[i]}\")\n",
    "    dendrogram(Z,labels=list_dataframe[i].index,orientation='top',color_threshold=1.5)\n",
    "    plt.savefig(f'Top_{list_top_k[i]} clustring.png',dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cluster into local\n",
    "#classter.to_excel(\"classterS.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Plot the correlation between the similarity metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(list_top_k)):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    sns.heatmap(data=list_dataframe[i].T.corr())\n",
    "    plt.title(f\"Correlation :Top_{list_top_k[i]}\")\n",
    "    plt.savefig(f'correlation ML_1M Top_{list_top_k[i]}.png',dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tThe end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
